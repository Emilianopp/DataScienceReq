{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('DataSci': conda)"
    },
    "interpreter": {
      "hash": "1ffc7893c692848b0397a1b2e1036e6e58d5f9824a51a1f3b5e4a482673fe79a"
    },
    "colab": {
      "name": "Copy of 5.2_Nueral_nets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import Sequential,layers\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import re\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \r\n",
        "from collections import Counter\r\n",
        "np.random.seed(4864)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Xnh2ytk8ZWe7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def cleanse(row):\r\n",
        "    row_clean = row.replace(\"-\", \" \")\r\n",
        "    row_clean = re.sub(\"[\\n]\", \" \",row_clean)\r\n",
        "    row_clean = re.sub(\"[.!?/\\()-,:]\", \"\",row_clean)\r\n",
        "    row_clean = row_clean.lower()\r\n",
        "    return row_clean\r\n",
        "\r\n",
        "def clean_df(df):\r\n",
        "    text = []\r\n",
        "    target = []\r\n",
        "    for row in df.iterrows():\r\n",
        "            row_clean = cleanse(row[1][1])\r\n",
        "            text.append(row_clean)\r\n",
        "    out = pd.DataFrame({'text':text,\"target\":df.out})\r\n",
        "    return out\r\n",
        "#Create data partitions\r\n",
        "df = pd.read_csv(f'/content/modeling_data.csv', encoding='latin-1')\r\n",
        "df = df.dropna()\r\n",
        "df = clean_df(df)\r\n",
        "max_length = max(df.text.apply(len))\r\n",
        "#Reduce amount of 0 targets as model was simply predicting 0 due to high proportion\r\n",
        "# description_indexes = df.index[df.target == 0 ]\r\n",
        "# df = df.drop(description_indexes[:int(len(description_indexes) * 0.5)]) \r\n",
        "#Shuffle dataframe\r\n",
        "# df = df.sample(frac=1)\r\n",
        "X_train, X_test, y_train, y_test=train_test_split(df.text, df.target, test_size=0.1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "NLFbkZLbZWe_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def counter_word(text):\r\n",
        "  count = Counter()\r\n",
        "  for i in text.values:\r\n",
        "    for word in i.split():\r\n",
        "      count[word] += 1 \r\n",
        "  return count"
      ],
      "outputs": [],
      "metadata": {
        "id": "OVvPNcfm4Du5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "count = counter_word(X_train)\r\n",
        "num_words = 30\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "z1qKyFrt4XiL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tokenizer = Tokenizer(num_words=num_words) \r\n",
        "tokenizer.fit_on_texts(texts = X_train)\r\n",
        "train_seq = tokenizer.texts_to_sequences(X_train)\r\n",
        "test_seq = tokenizer.texts_to_sequences(X_test)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\r\n",
        "def decode(text):\r\n",
        "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\r\n",
        "decode(train_seq[58])   "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'skills will you the to'"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U9pC94wXyAQE",
        "outputId": "a4326758-19e0-4404-a75b-f86ff85d08ab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Tokenize_data(data,tokinizer):\r\n",
        "  seq = tokenizer.texts_to_sequences(data)\r\n",
        "  padded = pad_sequences(seq,padding = 'post',truncating='post')\r\n",
        "  return padded"
      ],
      "outputs": [],
      "metadata": {
        "id": "MElSALQO9SLS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "t = [\"require to know R and Python\"]\r\n",
        "t = Tokenize_data(t,tokenizer)"
      ],
      "outputs": [],
      "metadata": {
        "id": "eOIGX7zYi_xG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_padded = pad_sequences(train_seq,padding = 'post',truncating='post',maxlen= max_length)\r\n",
        "test_padded = pad_sequences(test_seq,padding = 'post',truncating='post',maxlen= max_length)\r\n",
        "words = len(tokenizer.word_counts)"
      ],
      "outputs": [],
      "metadata": {
        "id": "zaTvLqR8ZWfA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = Sequential()\r\n",
        "model.add(layers.Embedding(num_words, 128, input_length=max_length))\r\n",
        "model.add(layers.LSTM(128,return_sequences =True))\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\r\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 1187, 128)         3840      \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 1187, 128)         131584    \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 151936)            0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 151937    \n",
            "=================================================================\n",
            "Total params: 287,361\n",
            "Trainable params: 287,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "id": "VX4KKgxDaCab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695f2899-b72b-4684-a637-fbc40cb407ca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "adam = tf.keras.optimizers.Adam(lr=.001, beta_1=0.9, beta_2=0.999, decay=0.01)\r\n",
        "\r\n",
        "model.compile(optimizer=adam,loss= 'binary_crossentropy',metrics = ['accuracy','Recall'])\r\n",
        "\r\n",
        "model.fit(x = train_padded, y= y_train,epochs=15,validation_split=.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 11s 192ms/step - loss: 0.6291 - accuracy: 0.6740 - recall: 0.0170 - val_loss: 0.5735 - val_accuracy: 0.6867 - val_recall: 0.0000e+00\n",
            "Epoch 2/15\n",
            "47/47 [==============================] - 8s 177ms/step - loss: 0.6625 - accuracy: 0.6801 - recall: 0.4021 - val_loss: 0.4446 - val_accuracy: 0.8133 - val_recall: 0.4231\n",
            "Epoch 3/15\n",
            "47/47 [==============================] - 8s 177ms/step - loss: 0.4429 - accuracy: 0.8256 - recall: 0.5085 - val_loss: 0.3882 - val_accuracy: 0.8494 - val_recall: 0.5385\n",
            "Epoch 4/15\n",
            "47/47 [==============================] - 8s 177ms/step - loss: 0.3912 - accuracy: 0.8504 - recall: 0.6021 - val_loss: 0.3579 - val_accuracy: 0.8373 - val_recall: 0.5577\n",
            "Epoch 5/15\n",
            "47/47 [==============================] - 8s 177ms/step - loss: 0.3674 - accuracy: 0.8524 - recall: 0.6404 - val_loss: 0.3470 - val_accuracy: 0.8494 - val_recall: 0.5769\n",
            "Epoch 6/15\n",
            "47/47 [==============================] - 8s 177ms/step - loss: 0.3541 - accuracy: 0.8632 - recall: 0.6745 - val_loss: 0.3489 - val_accuracy: 0.8494 - val_recall: 0.5769\n",
            "Epoch 7/15\n",
            "47/47 [==============================] - 8s 177ms/step - loss: 0.3489 - accuracy: 0.8518 - recall: 0.6340 - val_loss: 0.3392 - val_accuracy: 0.8795 - val_recall: 0.7115\n",
            "Epoch 8/15\n",
            "47/47 [==============================] - 8s 177ms/step - loss: 0.3445 - accuracy: 0.8565 - recall: 0.6511 - val_loss: 0.3385 - val_accuracy: 0.8735 - val_recall: 0.6923\n",
            "Epoch 9/15\n",
            "47/47 [==============================] - 8s 178ms/step - loss: 0.3398 - accuracy: 0.8551 - recall: 0.6532 - val_loss: 0.3457 - val_accuracy: 0.8494 - val_recall: 0.7308\n",
            "Epoch 10/15\n",
            "47/47 [==============================] - 8s 176ms/step - loss: 0.3347 - accuracy: 0.8672 - recall: 0.6915 - val_loss: 0.3375 - val_accuracy: 0.8675 - val_recall: 0.7115\n",
            "Epoch 11/15\n",
            "47/47 [==============================] - 8s 177ms/step - loss: 0.3349 - accuracy: 0.8645 - recall: 0.6723 - val_loss: 0.3396 - val_accuracy: 0.8614 - val_recall: 0.7115\n",
            "Epoch 12/15\n",
            "47/47 [==============================] - 8s 178ms/step - loss: 0.3284 - accuracy: 0.8672 - recall: 0.6745 - val_loss: 0.3366 - val_accuracy: 0.8614 - val_recall: 0.7115\n",
            "Epoch 13/15\n",
            "47/47 [==============================] - 8s 177ms/step - loss: 0.3301 - accuracy: 0.8692 - recall: 0.6936 - val_loss: 0.3379 - val_accuracy: 0.8614 - val_recall: 0.7115\n",
            "Epoch 14/15\n",
            "47/47 [==============================] - 8s 177ms/step - loss: 0.3270 - accuracy: 0.8699 - recall: 0.6915 - val_loss: 0.3353 - val_accuracy: 0.8554 - val_recall: 0.6346\n",
            "Epoch 15/15\n",
            "47/47 [==============================] - 8s 178ms/step - loss: 0.3236 - accuracy: 0.8699 - recall: 0.6894 - val_loss: 0.3346 - val_accuracy: 0.8494 - val_recall: 0.6154\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9cffc57510>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "metadata": {
        "id": "KeenrybFf_xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9edfa6-f424-493f-9cb7-22a3adb33ab7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we see validation metrics is being properly optimized lets train on all data"
      ],
      "metadata": {
        "id": "Sew-tCXnnxob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.evaluate(test_padded,y_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 83ms/step - loss: 0.3973 - accuracy: 0.8270 - recall: 0.5484\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.39734187722206116, 0.8270270228385925, 0.5483871102333069]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3N9h3jF95PL",
        "outputId": "e341b537-46ba-49a8-9c1a-b853f8917319"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def got_wrong(datax,datay,datax_pad,df):\r\n",
        "  binray_preds = np.reshape(np.round(model.predict(datax_pad)),(len(datay)))\r\n",
        "  true=np.array(datay)\r\n",
        "  q = binray_preds != true\r\n",
        "  match = datax[ binray_preds != true]\r\n",
        "  out = df.loc[match.index ]\r\n",
        "  return out"
      ],
      "outputs": [],
      "metadata": {
        "id": "vxYguLigMcs4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "incorrect = got_wrong(X_train,y_train,train_padded,df)\r\n",
        "incorrect.tong_values.csv')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model not very good"
      ],
      "metadata": {}
    }
  ]
}