{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo \n",
    "import pandas as pd \n",
    "import plotly as px \n",
    "import numpy as np \n",
    "import sys\n",
    "import pymongo\n",
    "from pymongo import MongoClient \n",
    "import re\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "sys.path.append(\"../DataPipe/\")\n",
    "from scraping.classes.DataBase.Mongo import *\n",
    "from scraping.classes.Role import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis_Processing:\n",
    "    def __init__(self,db:Mongo,role:Role):\n",
    "        self.db = db\n",
    "        self.role = role\n",
    "\n",
    "    def get_data(self) -> pd.DataFrame:\n",
    "        query_cursor = self.db.query({\"role\":self.role.title},{\"_id\":0},col = \"model_outputs\")\n",
    "        return pd.DataFrame(query_cursor)\n",
    "\n",
    "    def cleanse_sentence(self,sentence:str):\n",
    "        stop = stopwords.words('english')\n",
    "        sentence_clean = sentence.replace(\"-\", \" \")\n",
    "        sentence_clean = re.sub(\"[\\n]\", \" \",sentence_clean)\n",
    "        sentence_clean = re.sub(\"[.!?/\\()-,:]\", \"\",sentence_clean)\n",
    "        sentence_clean = sentence_clean.lower()\n",
    "        sentence_clean = \" \".join([word for word in sentence_clean.split(\" \") if word not in stop])\n",
    "        return sentence_clean\n",
    "\n",
    "    def word_count(self, text:pd.Series):\n",
    "        return Counter(self.cleanse_sentence(\" \".join(text)).split(\" \"))\n",
    "\n",
    "    def text_count(self,query_df):\n",
    "        urls = query_df.urls.unique()\n",
    "        count_arr = np.empty(shape = (len(urls)),dtype = Counter)\n",
    "        for i,url in enumerate(urls):\n",
    "            count_arr[i] = self.word_count(query_df[query_df.urls == url].text)\n",
    "        return count_arr \n",
    "\n",
    "    def per_role_analysis(self,keyword_path,insert = False,col = None,insert_key = None ):\n",
    "        tech_count = {}\n",
    "        tech_list = pd.read_csv(keyword_path ,index_col=[0]).iloc[:,0].str.lower()\n",
    "        for dicts in counters:\n",
    "            for word in dicts.keys():\n",
    "                if word in list(tech_list): \n",
    "                    if word not in tech_count.keys():\n",
    "                        tech_count.update({word:1})\n",
    "                    else:\n",
    "                        tech_count[word] += 1\n",
    "        if insert == True: \n",
    "            requests = [InsertOne({f\"{insert_key}\":tech_count,'role':self.role.title})]\n",
    "            self.db.db[col].bulk_write(requests)\n",
    "            print('successful insertion')\n",
    "        else: \n",
    "            return tech_count\n",
    "\n",
    "    def strip_digits_from_corupus(self,text):\n",
    "        subs = re.sub(\"[\\d+][+-]\", \"\",text)\n",
    "        subs = re.sub(\"[â€™']\", \"\",subs)\n",
    "        return(subs)\n",
    "        \n",
    "    def bigram_analysis(self,df,thresh = 5,insert = False,col = \"bigrams\"):\n",
    "        bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "        corpus_list = [self.strip_digits_from_corupus(sentence) for sentence in df.text]\n",
    "        corpus = ' '.join(corpus_list)\n",
    "        finder = BigramCollocationFinder.from_words(corpus.lower().split(\" \"),window_size=2)\n",
    "        finder.apply_freq_filter(thresh)\n",
    "        bigram_results = finder.score_ngrams(bigram_measures.pmi)\n",
    "        if insert == True: \n",
    "            requests =  [InsertOne({\"bigram\":x[0],\"pmi\":x[1],'role':self.role.title}) for x in bigram_results]\n",
    "            self.db.db[col].write(requests)\n",
    "            print(\"successful insertion\")\n",
    "        else: \n",
    "            return bigram_results \n",
    "\n",
    "    def store_analysis(self,db,data:dict):\n",
    "        [{\"bigram\":x[0],\"pmi\":x[1]} for x in analysis.bigram_analysis(df = query_df)]\n",
    "        requests = [InsertOne(x) for x in data]\n",
    "        scrape_table.collection.bulk_write(requests)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful insertion\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "db = Mongo(client)\n",
    "analysis = Analysis_Processing(db,Role(\"Software Engineer\") )\n",
    "query_df = analysis.get_data()\n",
    "counters = analysis.text_count(query_df)\n",
    "path_tech = r\"C:\\Users\\Emiliano\\Documents\\Git\\DataScienceReq\\data\\languages.txt\"\n",
    "tech_count = analysis.per_role_analysis(path_tech)\n",
    "path_packages = r'C:\\Users\\Emiliano\\Documents\\Git\\DataScienceReq\\data\\DS_packages.txt'\n",
    "analysis.per_role_analysis(path_packages,insert = True ,col = \"packages\",insert_key = \"packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql': 1, 'object': 1, 'python': 1, 'java': 1, 'kotlin': 1, 'scala': 1}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_count"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ffc7893c692848b0397a1b2e1036e6e58d5f9824a51a1f3b5e4a482673fe79a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('DataSci': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
