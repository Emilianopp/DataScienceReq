{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Test Naive Bayes Classifier to Classify Qualification Text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets try a Naive bayes model.\r\n",
    "\r\n",
    "naive Bayes regularly generalizes well into data as it is a high bias model, with low variance\r\n",
    "\r\n",
    "This means it is not a very complex model and does not often overfit to the training set which is a great place for us to start"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "#Create data partitions\r\n",
    "df = pd.read_csv('./labeled_descriptions.csv', encoding='latin-1')\r\n",
    "df = df.dropna()\r\n",
    "df.head()\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test=train_test_split(df.text, df.out, test_size=0.33,random_state = 4864)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform data into sklearns compressed count vector format "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "count_vect = CountVectorizer()\r\n",
    "X_train_counts = count_vect.fit_transform(X_train)\r\n",
    "X_test_counts = count_vect.transform(X_test)\r\n",
    "X_train_counts.shape,X_test_counts.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((52, 1685), (27, 1685))"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform data into frequencies rather than raw count to avoid extreme outliars."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "X_train_freq = TfidfTransformer(use_idf=False).fit_transform(X_train_counts)\r\n",
    "X_test_freq = TfidfTransformer(use_idf=False).transform(X_test_counts)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train model with training set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "naive = MultinomialNB().fit(X_train_freq, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "round(naive.score(X_test_freq,y_test),2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems like we have achieved great accuracy on our first model. \r\n",
    "\r\n",
    "We will keep in this in mind but lets try a support vector machine classifier simply to compare"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "from sklearn import svm\r\n",
    "vector_machine = svm.SVC()\r\n",
    "vector_machine.fit(X_train_freq,y_train)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "vector_machine.score(X_test_freq,y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "X_train_counts.toarray().shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(52, 1685)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wow seems like we achieved 100% accuracy on our test set\r\n",
    "\r\n",
    "This is not as surprising as qualification text should be fairly distinguishable from description text. \r\n",
    "\r\n",
    "This is great and means we can export our model and use it to help us identify qualification text in our scraped data"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('DataSci': conda)"
  },
  "interpreter": {
   "hash": "1ffc7893c692848b0397a1b2e1036e6e58d5f9824a51a1f3b5e4a482673fe79a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}